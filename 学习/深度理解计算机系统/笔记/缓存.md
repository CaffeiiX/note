位于寄存器的缓存器是存储主存储器中经常访问的块，请求的大多数数据都是该缓存器提供。
![[Pasted image 20221225221229.png]]

![[Pasted image 20221225221321.png]]

![[Pasted image 20221225221336.png]]

1. 根据组索引找到组所在的位置
2. 根据标记进行对比，找到缓存所在的组内位置
3. 有效位是否有效，有效则说明缓存命中，根据块偏移提取出高速缓存中的内容
4. 未命中则需要从内存中获取地址进行覆盖。
组内只有一行的时候为直接缓存索引，对于直接缓存索引来说，由于组仅能存储一行，所以在对同一组进行频繁读取的时候会造成反复覆盖，对此引入了一组内多行的情况，即E路组相连缓存。不同的时候对于标记位，进行并行搜索，对组内的所有行的标记位均进行比较。最近最少原则，替换最少使用的缓存内容。

**写入操作**
对缓存中的块内数据进行写操作
1. 立即将块写入内存，内存始终保持缓存的镜像（耗时）
2. 写回：不会直接写入内存，直到缓存覆盖该块数据。当缓存进行覆盖时，检查修改位，如果是的话则进行写回。
如果写的字不在缓存中
1. 写分配：将内存中的内容写入缓存后再进行操作
2. 非写分配：直接对内存中的数据进行写入

![[Pasted image 20221226233653.png]]
L1 d-cache: 数据缓存
L1 i-cache: 指令缓存
L1 -> L2 -> L3

评价缓存的指标
1. 未命中率： L1 3%-10%
2. 命中时间：不同级别的缓存的时间周期是不同的
未命中惩罚：缓存中没有命中，需要从内存中进行取相应的数据

99%的命中率是97%命中率的两倍
97%hits :  $$1 cycle + 0.03*cycles = 4cycles$$
99%hits:
$$1cycle + 0.01*100cycles = 2cycles$$


编写缓存友好的代码，关注内循环中的未命中情况，使用局部变量可能会将其存入寄存器中，但是全局变量则不会。步长为1是缓存友好的，但是步长为2的则不一定。
**存储器山**：描绘了一种称为“吞吐量”或“读带宽”的衡量标准，从内存中读取的字节数。
```C
long data[MAXELEMS];
int test(int elems, int stride){
	long i, sx2=stride*2, sx3=stride*3, sx4 =stride*4;
	long acc0 = 0, acc1 = 0, acc2 = 0, acc3 = 0;
	long length = elems, limit = length - sx4;
	for(i = 0; i < limit; i += sx4){
		acc0 = acc0 + data[i];
		acc1 = acc1 + data[i + stride];
		acc2 = acc2 + data[i + sx2];
		acc3 = acc3 + data[i + sx3];
	}
	for(; i < length; i ++){
		acc0 = acc0 + data[i]
	}
	return ((acc0 + acc1) + (acc2 + acc3));
}
```
![[Pasted image 20221227002752.png]]

随着步长的增加，减少了空间局部性，从而吞吐量减少。
随着读取的需要的内存变大，空间局部性减少，吞吐量减少，不同需要的缓存从不同的高速缓存级别中读取。
对于步长为1的情况下，可以看出大小在L3的时候吞吐量才会出现一个降低，这可能是由于硬件识别出步长为1的情况，积极的将L2的缓存复制到上一级缓存中，使得其能保持一个很高的读取速度。

**矩阵乘法**
可以具有六种排列方法
```C
for(i = 0; i < n; i ++){
	for(j = 0 ; j < n ; j ++){
		sum = 0.0;
		for(k = 0; k < n; k ++ )
			sum += a[i][k] * b[k][j];
		c[i][j] = sum;
	}
}
```
ijk
![[Pasted image 20221227003910.png]]
未命中率，列模式的情况下，每次都需要进行一次覆盖
|mode|A|B|C|
|--|--|--|--|
|ijk|0.25|1.0|0.0|
|kij|0.0|0.25|0.25|
|jki|1.0|0.0|1.0|

kij需要额外存储，会对时间减慢
写操作比读操作更为灵活，因为有**写回**这一操作
![[Pasted image 20221227004837.png]]

**改善时间局部性**
采用**阻塞**的技术
比如对于矩阵乘法来说，可以通过子块的方法，由于子块的存在，则可以复用这部分的缓存，即从时间局部性上对于速度进行优化。


总结一下就是，两个相乘的矩阵size都很大，远大于分块的size，然后分块的矩阵size又刚好都能放进cache中。满足这两个条件，分块可以实现减小访存耗时。命中cache的原因：首先，矩阵都是按行优先方向存储的，二维矩阵实际存储也是拉成一维存的，对于矩阵B，每次访问都是访问一列，在一维的角度上就是不连续的，如果不分块，由于size很大，cache中连B的一列都存不下，所以每次访问B的新一列，都不能命中cache。如果分块，假设块大小16*16，访问块中B的第0列都会miss，但是第0列都被写入cache中，等下次访问1到15列就都命中了。 至于分块和不分块结果等价，可以假设矩阵A分块大小是1行多列，矩阵B分块大小是多行1列这种特殊情况，简单情况想通了，可以类推到多行多列的分块。